{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/colmhiggs11/Machine_Learning_21_CH/blob/main/Images/scipylogo.png?raw=true\" style = \"height:125px;width:300px;\" Title= \"SciPy Sub Packages\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy is a Python library used to solve mathematical and scientific problems. It is built on Numpy. Numpy uses array data and has basic operation like sorting and indexing. SciPy contains numerical code. It is a library containing full versions of mathematical and scientific functions. The sub packages contained in SciPy are shown in the image below. In this notebook we will be looking at SciPy Stats.\n",
    "\n",
    "<img src=\"https://github.com/colmhiggs11/Machine_Learning_21_CH/blob/main/Images/Scipy.png?raw=true\" style = \"height:400px;width:550px;\" Title= \"SciPy Sub Packages\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy Stats\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy Stats module is one of the many sub packages of the SciPy library. It is made up of probability distributions (both continuous and discrete), summary and frequency statistics, correlation functions and statistical tests,kernel density estimation and a lot more. It's content is constantly being updated due to the open source nature of SciPy. SciPy has many contributors and is located on Github. [[1]](#1) \n",
    "\n",
    "The two distribution classes rv_continuous and rv_discrete are made for subclassing. They are normally used if you need a distribution which is not already defined in scipy.stats There are more than 80 continuous random variables and over 10 discrete random variables implemented into these classes.\tTo get a full list of the statistic functions in scipy.stats you can use the following code: `info(stats) `\n",
    "\n",
    "Probability distributions show us the Likelihood of a particular outcome. \n",
    "The are underneath the curve must add up to 1 as shown below. [[2]](#2) \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/colmhiggs11/Machine_Learning_21_CH/blob/main/Images/PDF.PNG?raw=true\" style = \"height:300px;width:500px;\" Title= \"SciPy Sub Packages\"/>\n",
    "\n",
    "<img src=\"https://github.com/colmhiggs11/Machine_Learning_21_CH/blob/main/Images/Scipy.png?raw=true\" style = \"height:300px;width:500px;\" Title= \"SciPy Sub Packages\"/>\n",
    "\n",
    "__Continuous distributions__\n",
    "Typically use continuous random variables such as measurements. Examples include height, the time required to complete a task etc.\n",
    "This is represented by the area under a curve or the integral. \n",
    "\n",
    "__Discrete distributions__\n",
    "Typically use discrete random variables such as count values . Examples of discrete random variables include the number of pets you own, attendance at a school, the number of patients in a hospital.\n",
    "The probability distribution is a list of probabilities associated with each of its possible values. It is called probability mass function.\n",
    "\n",
    "There are a number of other functions within scipy.stats that are very useful.\n",
    "\n",
    "|Name| Description|\n",
    "|:-------------|:-------------|\n",
    "|Summary statistics |Used to return descriptive statistics. For decoding values in the output. Minimum, Maximum, Count, Mean etc.|\n",
    "|Frequency statistics   |Typically used to return scores and frequency histograms|\n",
    "|Correlation functions - f_oneway(args[, axis]) Perform one-way ANOVA. |Used to analyse correlation between variables or features in datasets. For quantifying the strength of the relationship |\n",
    "|Statistical tests |Used in hypothesis testing to determine whether input variables have significant relationship with the target variables. Estimation of difference between two or more groups.| \n",
    "\n",
    "In Statistical tests there is an assumption made and the testing is based onhow likely the assumption will prove to be false. Initially a null hypothesis is assumed which means there is no difference or relationship between variables. The p-probability value deternines whether there is a significant relationship between the input and target variables. If the p-value is below th threshold typically 0.05. Then there is said to be a relationship between the variables. For the purpose of this notebook we will be focussing on the ANOVA statistical test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA (ANalysis Of VAriance)\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA is a statistical test as mentioned above. It is typically used when a t-test that would deal with two samples is not able to be used because there are more than two samples to be tested.\n",
    "Anova uses the F-Test to check whether the group means are equal and also looks for the variation within the samples. There is only one dependent variable in the model. The formula for completing a one-way ANOVA test is as follows:  https://www.ics.uci.edu/~jutts/8/Lecture28Compact.pdf\n",
    "\n",
    "___\n",
    "$$\n",
    "F = \\frac{Explained \\; Variance}{Unexplained\\; Variance} or\\frac{ Variance\\; between \\;Groups}{ Variance \\;within \\;Groups} = \\frac{Sum \\;of \\;Squares\\; between\\; groups}{Sum \\;of \\;Squares\\; for \\;error} = \\frac{MST}{MSE} = \\frac{Mean \\;Squared \\;Error \\;Treatments}{Mean \\;Squared \\;Error } = \\frac{\\frac{SS_B}{DfT}}{\\frac{SS_W}{DfE}} = \\frac{\\frac{SS_B}{k-1}}{\\frac{SS_W}{N-k}}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "$$ Where,$$\n",
    "\n",
    "\n",
    "$$SS_b = \\sum_{i}^{} n_i{(y_i-y)^2}$$\n",
    "\n",
    "$$SS_bW = \\sum_{ij}^{} {(y_{ij}-y_i)^2}$$\n",
    "\n",
    "$$ Where,$$\n",
    "\n",
    "\n",
    "$$y_i = Sample \\;mean \\;in \\;the\\; i^{th} \\;group$$\n",
    "\n",
    "$$n_i = number \\;of \\;observation \\;in\\; the \\;i^{th}\\; group$$\n",
    "\n",
    "$$y_i = total\\; mean \\;of \\;the \\;data$$\n",
    "\n",
    "$$k = total \\;number \\;of \\;groups$$\n",
    "\n",
    "$$y_{ij} = j^{th} \\;observation\\; out \\;of \\;k \\;group$$\n",
    "\n",
    "$$N = Overall\\; sample\\; size$$\n",
    "\n",
    "\n",
    "### Initially we look at the ANOVA hypotheses:\n",
    "\n",
    "\n",
    "|Name| formula |Description|\n",
    "|:-------------|:-------------|:-------------|\n",
    "|Null hypothesis |$$H_0:  = \\mu_1 = \\mu_2...=\\mu_p$$|This is where there is no variation between the mean values in the groups|\n",
    "|Alternative hypothesis   |$$H_0:  All \\; \\mu \\;are  \\;not  \\;equal$$ |This is where at least one of the groups mean value differs from the other groups|\n",
    "\n",
    "\n",
    "### Next we look at the ANOVA assumptions: \n",
    "\n",
    "|Title| Description |\n",
    "|:-------------|:-------------|\n",
    "|1. The dependent variable must be continuous  |Has to be a measured value. Eg(Test scores(0-100%), Weight(kg), Height(m) etc.|\n",
    "|2. The independent variables must consist of 2/3 categorical independent groups  |One-way ANOVA is used normally when there are more than two categorical,independent groups Eg(salary range(Low,Medium,High), ethnicity(Caucasian, Hispanic, African, African-American) etc.|\n",
    "|3. Must be no relationship between observations  |To use the One-wa Anova test no single observation in a group can be part of another group. |\n",
    "|4. There should be no significant outliers  |Outliers that don't follow the typical pattern within the data and have values that largely differ from the mean reduce the validity and accuracy of the Anova one-way test.|\n",
    "|5. Dependent variable should be normally distributed for each category  |Shapiro-Wilk test is used here to test for normality.|\n",
    "|6. There needs to be homogeneity of variances |Levene's test for homogeneity of variances is used here. If this test fails (p-value of lower than 0.05) then a Welch Anova test is required instead of a one-way Anova|\n",
    "[[3]](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "The dataset that will be used in this ANOVA testing is the Student Performance dataset that looks into the highest level of education received by the parents and what effect is has on the childs Math, Reading and Writing score. The dataset also looks at ethnicity, the types of lunch received and gender. The dataset used can be found at the following location - https://www.kaggle.com/barkhaverma/student-performance-analysis. There are 1000 observations in the dataset, the first thing to do is to check that no data is missing. As seen below there is no missing data. We are going to be looking at the effect that the parents eduction has on the child's mathematical ability so we need to see how many categories we have in this group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"StudentPerformance.csv\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 1 The dependent variable must be continuous\n",
    "---\n",
    "\n",
    "The dependent variable in this case will be the math score. Math scores in America were below average according to the PISA results [[4]](#4)so this is the score that we will be focusing on. As the is a score from 0-100, this is seen as a continuous variable and passes assumption 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['math score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 2 The independent variables must consist of 2/3 categorical independent groups\n",
    "---\n",
    "\n",
    "To check this we check the number of unique values in the Parent_Eduction column. (Name changed for ease of use). As we can see below there are 6 unique values.\n",
    "The values in this dataset look to have some crossover. There are two sets of columns that have similar identifiable names. For the purpose of this analysis both \"some college\" and \"some high school\" will be remove as they are covered in the various degree's and high school categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_DF_Math = df.rename({'parental level of education': 'Parent_Education'}, axis=1)  # new method\n",
    "\n",
    "Num_unique = New_DF_Math.Parent_Education.nunique()\n",
    "\n",
    "print(f'There are {Num_unique} categorical groups in this variable')\n",
    "print(f'These are:\\n{New_DF_Math.Parent_Education.value_counts()} categorical groups in this variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['gender', 'race/ethnicity', 'lunch', 'test preparation course', 'reading score',\n",
    "       'writing score']\n",
    "\n",
    "Anova_DF = New_DF_Math.drop(drop_cols, axis = 1)\n",
    "Anova_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HS = Anova_DF[Anova_DF['Parent_Education'] == \"high school\"]\n",
    "df1 = Anova_DF[Anova_DF['Parent_Education'] == \"some high school\"]\n",
    "\n",
    "a = df_HS.describe().T\n",
    "b = df1.describe().T\n",
    "print(f'{a}\\n {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anova_df1 = Anova_DF[~Anova_DF['Parent_Education'].isin(['some high school','some college'])]\n",
    "Anova_df1.Parent_Education.value_counts()\n",
    "print(f'There are now {Anova_df1.Parent_Education.nunique()} categorical groups in this variable')\n",
    "print(f'---------------------------')\n",
    "print(Anova_df1.Parent_Education.value_counts())\n",
    "print(f'---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 3 Must be no relationship between observations\n",
    "---\n",
    "\n",
    "The third assumption requires us to separate each of the categorical values into their own dataframe to ensure no one group is part of another group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HS = Anova_DF[Anova_DF['Parent_Education'] == \"high school\"]\n",
    "df_AD = Anova_DF[Anova_DF['Parent_Education'] == \"associate's degree\"]\n",
    "df_BD = Anova_DF[Anova_DF['Parent_Education'] == \"bachelor's degree\"]\n",
    "df_MD = Anova_DF[Anova_DF['Parent_Education'] == \"master's degree\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 4 There should be no significant outliers\n",
    "---\n",
    "\n",
    "Firstly we plot the groups on histograms to see if there are any glaringly obvious outliers. From the histogram it looks like there may be one in the High School group. The boxplots below show us that there is an outlier in this data.[[5]](#5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 7))\n",
    "\n",
    "sns.distplot(df_HS[\"math score\"], kde=True, rug=False, ax=ax[0, 0], color=\"b\")\n",
    "sns.distplot(df_AD[\"math score\"], kde=True, rug=False, ax=ax[0, 1], color=\"r\")\n",
    "sns.distplot(df_BD[\"math score\"], kde=True, rug=False, ax=ax[1, 0], color=\"g\")\n",
    "sns.distplot(df_MD[\"math score\"], kde=True, rug=False, ax=ax[1, 1], color=\"orange\")\n",
    "\n",
    "fig.legend(labels=['High School','Associate\\'s Degree','Bachelor\\'s Degree','Master\\'s Degree'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12.5, 7.5))\n",
    "       \n",
    "ax1 =sns.boxplot(df_HS[\"math score\"],ax=ax[0, 0],color=\"b\")\n",
    "ax2 =sns.boxplot(df_AD[\"math score\"],ax=ax[0, 1],color=\"r\")\n",
    "ax3 = sns.boxplot(df_BD[\"math score\"],ax=ax[1, 0],color=\"g\")\n",
    "ax4 = sns.boxplot(df_MD[\"math score\"],ax=ax[1, 1],color=\"orange\")\n",
    "\n",
    "# https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib\n",
    "ax1.title.set_text('High School')\n",
    "ax2.title.set_text('Associate\\'s Degree')\n",
    "ax3.title.set_text('Bachelor\\'s Degree')\n",
    "ax4.title.set_text('Master\\'s Degree')\n",
    "plt.tight_layout()\n",
    "\n",
    "df_list = [df_HS, df_AD, df_BD, df_MD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "#https://www.statisticshowto.com/probability-and-statistics/z-score/ \n",
    "for i in range(len(df_list)):\n",
    "    z = np.abs(stats.zscore(df_list[i][\"math score\"]))\n",
    "    print(f'Less than -3 std: {np.where(z < -3)}  | Greater than 3 std:{np.where(z > 3)}')\n",
    "\n",
    "print(\"\\nThe value that is identified as an outlier is:\")\n",
    "print(f'--------------------------------\\n{df_HS.iloc[190]}')\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "# https://stackoverflow.com/questions/28679930/how-to-drop-rows-from-pandas-data-frame-that-contains-a-particular-string-in-a-p\n",
    "df_HS1 = df_HS[~df_HS['math score'].isin(['8'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier is identified above and is removed from the dataset as shown above using the Z-score test that says an observation is an outlier when it is more than 3 times the standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 5 Dependent variable should be normally distributed for each category\n",
    "---\n",
    "\n",
    "The Shapiro-Wilk test [[6]](#6) is completed to determine if the dependent variable is normally distributed for each category. When the P-value is greater than 0.05 the data to be normally distributed. As shown below the data for the High School & Masters Degree categories are normally distributed. The other two categories are just under the threshold for being a normally distributed category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list1 = [df_HS1, df_AD, df_BD, df_MD]\n",
    "labels=['High School','Associate\\'s Degree','Bachelor\\'s Degree','Master\\'s Degree']\n",
    "for i in range(len(df_list1)):\n",
    "    for j in range(len(labels)):\n",
    "        pvalue = stats.shapiro(df_list[i]['math score'])[1]\n",
    "    print(f'Shapiro Wilk test for {labels[j]} - p value: {pvalue:.3f}: Index{[i]}')\n",
    "    if pvalue<0.05:\n",
    "        print(\"Data is **NOT** Normally distributed\")\n",
    "    else:\n",
    "        print(\"Data is Normally distributed!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assumption 6 There needs to be homogeneity of variances\n",
    "---\n",
    "Levene test is used on the two Normally distributed categories to see if there is homogeneity of variances between them.\n",
    "As seen below there is so the ANOVA f_oneway test can commence. Although with only two categories a t-test could also be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvaluea = stats.levene(df_list1[0]['math score'], df_list1[2]['math score'])\n",
    "print(f'High School & Bachelor\\'s Degree: \\n{pvaluea}')\n",
    "print(f'-----------------------------------------------------------------')\n",
    "if pvaluea[1]<0.05:\n",
    "    print(f'There is no homogeneity of variances as p-value is less than 0.05')\n",
    "else:\n",
    "    print(f'There is homogeneity of variances as p-value is greater than 0.05')\n",
    "    print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ANOVA Test f_oneway - Test for significant difference\n",
    "---\n",
    "\n",
    "Test to see if there is significant difference between categories. Similar to other tests a p-value less than 0.05 would indicate that there is a significant difference. Whereas a value greater than 0.05 would indicate no significant difference. As shown below, there is a fairly significant difference as the p-value came out to be 0.00003. [[7]](#7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue1 = stats.f_oneway(df_list1[0]['math score'], df_list1[2]['math score'])\n",
    "print(f'High School & Bachelor\\'s Degree: \\n{pvalue1}')\n",
    "print(f'-------------------------------------------------------------------------------------')\n",
    "print(f'Anova test: Groups are significantly different as p-value ({pvalue1[1]:.5f}) is less than 0.05')\n",
    "print('-------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Welch’s ANOVA in Python & Games-Howell post-hoc test\n",
    "---\n",
    "\n",
    "Welch’s ANOVA test [[8]](#8) is completed when the assumption of equal variances is proved to be false. This could have been completed after the Shapiro test on the categories that were not Normally distributed. The p- value shown below is a lot less than 0.05 so we can reject the null hypothesis which would have been that exam scores would have been equal for the four types of Parents education.The Games-Howell post-hoc test is used to determine which groups means vary from eachother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.welch_anova(dv='math score', between='Parent_Education', data=Anova_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_gameshowell(dv='math score', between='Parent_Education', data=Anova_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data we can see that there is a significant difference between the following combinations of groups.\n",
    "\n",
    "\n",
    "| Significant Difference between groups||\n",
    "|:-------------|:-------------|\n",
    "|associate's degree |high school|\n",
    "|bachelor's degree |high school|\n",
    "|high school |master's degree|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "|||\n",
    "|:-------------|:-------------|\n",
    "|<a id=\"1\">[1]</a> https://github.com/scipy/scipy |<a id=\"2\">[2]</a> https://en.ppt-online.org/412169 Normal Probability Distributions : Copyright © 2010, 2007, 2004 Pearson Education, Inc.|\n",
    "|<a id=\"3\">[3]</a> https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php |<a id=\"4\">[4]</a> https://www.oecd.org/pisa/publications/pisa-2018-results.html|\n",
    "|<a id=\"5\">[5]</a> https://towardsdatascience.com/create-and-customize-boxplots-with-pythons-matplotlib-to-get-lots-of-insights-from-your-data-d561c9883643 |<a id=\"6\">[6]</a> https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html |\n",
    "|<a id=\"7\">[7]</a> https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/ |<a id=\"8\">[8]</a>https://www.statology.org/welchs-anova-in-python/ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other References used:\n",
    "\n",
    "- https://www.youtube.com/watch?v=ITf4vHhyGpc\n",
    "- https://www.youtube.com/watch?v=_X45N7ERtY4\n",
    "- https://www.reneshbedre.com/blog/anova.html\n",
    "- https://www.pythonfordatascience.org/anova-python/\n",
    "- https://analyticsindiamag.com/a-complete-python-guide-to-anova/\n",
    "- https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
